---
title: heketi
date: 2025-04-29 22:29:00 +0800
categories: [分布式存储,glusterfs,heketi]
tags: [分布式存储]
toc: true
---


框架

![alt text](/assets/images/image.png)
 
目前我们仅使用 1 个集群一个zone 的模式，即所有的节点都在一个集群的一个 zone 里 面。创建顺序为：

1. 创建集群
2. 集群中增加节点
3. 节点上面增加设备
4. 集群上创建卷(使用节点中的设备)

#### 一、安装heketi
保证gluster也已经安装
安装heketi 
yum list heketi --showduplicates | sort -r
`yum install -y heketi heketi-client`
创建公私钥对到指定目录 ssh-keygen -t rsa -f /etc/heketi/heketi_key -N ''
修改/etc/heketi/heketi.json文件
```
{
  "_port_comment": "Heketi Server Port Number",
  "port": "8080",                                                        #服务端口

  "_use_auth": "Enable JWT authorization. Please enable for deployment",
  "use_auth": false,

  "_jwt": "Private keys for access",
  "jwt": {
    "_admin": "Admin has access to all APIs",
    "admin": {
      "key": "123456"                                                     #管理员密码
    },
    "_user": "User only has access to /volumes endpoint",
    "user": {
      "key": "test"
    }
  },

  "_glusterfs_comment": "GlusterFS Configuration",
  "glusterfs": {
    "_executor_comment": [
      "Execute plugin. Possible choices: mock, ssh",
      "mock: This setting is used for testing and development.",
      "      It will not send commands to any node.",
      "ssh:  This setting will notify Heketi to ssh to the nodes.",
      "      It will need the values in sshexec to be configured.",
      "kubernetes: Communicate with GlusterFS containers over",
      "            Kubernetes exec api."
    ],  
    "executor": "ssh",                                        #执行方式ssh

    "_sshexec_comment": "SSH username and private key file information",
    "sshexec": {
      "keyfile": "/root/.ssh/id_rsa",                         #使用的私钥文件路径
      "user": "root",                                         #ssh的用户
      "user": "heketi",                                       
      "sudo": true,                                           #如果是普通用户需要加上"sudo": "true"
      "port": "22",                                           #端口
      "fstab": "/etc/fstab"                                   #fstab文件的路径
    },

    "_kubeexec_comment": "Kubernetes configuration",
    "kubeexec": {
      "host" :"https://kubernetes.host:8443",
      "cert" : "/path/to/crt.file",
      "insecure": false,
      "user": "kubernetes username",
      "password": "password for kubernetes user",
      "namespace": "OpenShift project or Kubernetes namespace",
      "fstab": "Optional: Specify fstab file on node.  Default is /etc/fstab"
    },

    "_db_comment": "Database file name",
    "db": "/var/lib/heketi/heketi.db",

    "_loglevel_comment": [
      "Set log level. Choices are:",
      "  none, critical, error, warning, info, debug",
      "Default is warning"
    ],
    "loglevel" : "info"
  }
}
```
* 如果是root用户
  
修改/usr/lib/systemd/system/heketi.service将启动用户改为root
```
[root@localhost ~]# more /usr/lib/systemd/system/heketi.service
[Service]
User=root
```
创建集群，添加node和devices的节点需要和其他节点设置免密，和当前节点自身的免密也要做。后面添加node和device都需要免密才可以添加。免密一定要做！
[root@master ~]# ssh-copy-id  master
[root@master ~]# ssh-copy-id  node01
[root@master ~]# ssh-copy-id  node02

* 如果是普通用户
  
修改配置文件所在目录的属主属组
chown heketi:heketi /etc/heketi/ -R 
chown heketi:heketi /var/lib/heketi -R 
修改/usr/lib/systemd/system/heketi.service将启动用户改为heketi
```
[root@localhost ~]# more /usr/lib/systemd/system/heketi.service
[Service]
User=heketi
```
修改/etc/heketi/heketi.json为普通用户，并添加sudo行
      "user": "heketi", 
      "sudo": true,
各节点的heketi普通用户都需要有sudo权限
[root@master heketi]# echo "heketi    ALL=(ALL)       NOPASSWD: ALL" >> /etc/sudoers
[root@node01 heketi]# echo "heketi    ALL=(ALL)       NOPASSWD: ALL" >> /etc/sudoers
[root@node02 heketi]# echo "heketi    ALL=(ALL)       NOPASSWD: ALL" >> /etc/sudoers
ssh免密码信任，和当前节点自身的免密也要做。后面添加node和device都需要免密才可以添加。免密一定要做！！！
[heketi@master ~]$ ssh-copy-id  master
[heketi@master ~]$ ssh-copy-id  node01
[heketi@master ~]$ ssh-copy-id  node02

设置开机自启并启动
systemctl daemon-reload
systemctl enable --now heketi
systemctl status heketi
启动成功后执行验证一下
```
curl 127.0.0.1:8080/hello
Hello from Heketi
```
 
#### 二、集群 cluster
heketi 支持 Restful 接口和 heketi-cli 客户端访问， 目前采用 heketi-cli 进行访问，例如：
  1.  heketi-cli --server http://localhost:8080 --user admin --secret "123456"   
  2.  后续为便于方便，把上面命名 alias 为 hc，在.bashrc文件中添加
       alias hc='heketi-cli --server http://localhost:8080 --user admin --secret "123456" '
heketi 支持创建多个集群， 目前我们仅使用一个集群。
##### 1.集群相关操作
Usage:
  heketi-cli cluster [command]

Available Commands:
  create      Create a cluster
  delete      Delete the cluster
  info        Retrieves information about cluster
  list        Lists the clusters managed by Heketi
  setflags    Set flags on a cluster
###### 1.1.创建集群
    hc cluster create
创建成功以后返回 cluster id
###### 1.2.查看所有集群
    hc cluster list --json
加上-—json，返回结果为 json 格式 (备注：所有查询接口兼可使用—json 参数返回为 json 结果)
###### 1.3.删除集群
  hc cluster delete xxxx
xxxx 为 cluster id，可以使用 cluster list 查询得到
删除cluster前需要先删除device和node
###### 1.4.查看集群详情
  hc cluster info xxxx
xxxx 为 cluster id，可以使用 cluster list 查询得到
```
[root@glusterfs-node1 ~]# hc cluster info 6089a20345524da0b7a6559b46a9df62
Cluster id: 6089a20345524da0b7a6559b46a9df62
Nodes:
3f5ec05aebbfbabc4e7c0020a60786ae
f30cea782a8244842f445ffd44d4578e
Volumes:

Block: true

File: true
```
 
Nodes:  集群所包含的节点
Volumes：集群所创建的卷

###### 1.5 查看集群磁盘状态(heketi9.0以上支持)

1.     hc cluster getdiskstatus xxxx
2.     # xxxx 为 cluster id，可以使用 cluster list 查询得到

 ![alt text](/assets/images/image-1.png)
 
###### 1.6 查看集群可以创建的最大卷(heketi9.0以上支持)

1.     hc cluster getvolmaxsize xxxx
2.     # xxxx 为 cluster id，可以使用 cluster list 查询得到
![alt text](/assets/images/image-2.png)
 
MaxAllowCreateVolSize:  可以创建的最大卷 (单位为 G)
AvaildDiskCnt ：  可用的最大磁盘数目
AvaildNodeCnt：可用的最大节点数目


###### 1.7 查询集群节点上面空闲的磁盘数目(heketi9.0以上支持)

1.     hc cluster querydevices xxxx
2.     # xxxx 为 cluster id，可以使用 cluster list 查询得到
![alt text](/assets/images/image-3.png)
 
备注：已经添加到 heketi 集群里面的磁盘不再展示，此处仅展示可以添加到heketi 集群里面 的磁盘。
##### 2.节点相关操作
```
Heketi Node Management

Usage:
  heketi-cli node [command]

Available Commands:
  add         Add new node to be managed by Heketi
  delete      Deletes a node from Heketi management
  disable     Disallow usage of a node by placing it offline
  enable      Allows node to go online
  info        Retrieves information about the node
  list        List all nodes in cluster
  remove      Removes a node and all its associated devices from Heketi
  rmtags      Removes tags from a node
  settags     Sets tags on a node
```
###### 2.1. 添加节点
  $ heketi-cli node add \
      --zone=1 \
      --cluster=<clusterid> \
      --management-host-name=<ip或主机名> \
      --storage-host-name=<ip或主机名>
```
[root@glusterfs-node1 ~]# hc  node add  --cluster=6089a20345524da0b7a6559b46a9df62 --management-host-name=192.168.189.132 --sto
rage-host-name=192.168.189.132 --zone=1Node information:
Id: 3f5ec05aebbfbabc4e7c0020a60786ae
State: online
Cluster Id: 6089a20345524da0b7a6559b46a9df62
Zone: 1
Management Hostname 192.168.189.132
Storage Hostname 192.168.189.132
```
###### 2.2. 查看节点
`hc node list`
```
[root@glusterfs-node1 ~]# hc node list
Id:3f5ec05aebbfbabc4e7c0020a60786ae	Cluster:6089a20345524da0b7a6559b46a9df62
Id:f30cea782a8244842f445ffd44d4578e	Cluster:6089a20345524da0b7a6559b46a9df62
```
###### 2.3. 删除节点
删除节点前需要先删除节点上的设备
执行`hc node list`查看<nodeid>
可以使用`hc node info <nodeid>`查看节点和<nodeid>的对应关系
 $ heketi-cli node delete <nodeid>
```shell
[root@glusterfs-node1 ~]# hc node delete f30cea782a8244842f445ffd44d4578e
Error: Unable to delete node [f30cea782a8244842f445ffd44d4578e] because it contains devices
节点上有device，需要先删除设备再删除节点
删除设备后再删除节点
[root@glusterfs-node1 ~]# hc node info 3f5ec05aebbfbabc4e7c0020a60786ae
Node Id: 3f5ec05aebbfbabc4e7c0020a60786ae
State: online
Cluster Id: 6089a20345524da0b7a6559b46a9df62
Zone: 1
Management Hostname: 192.168.189.132
Storage Hostname: 192.168.189.132
Devices:                                  #devices下为空
[root@glusterfs-node1 ~]# hc node delete 3f5ec05aebbfbabc4e7c0020a60786ae
Node 3f5ec05aebbfbabc4e7c0020a60786ae deleted
```
##### 3. device相关操作
Usage:
  heketi-cli device [command]

Available Commands:
  add         Add new device to node to be managed by Heketi
  delete      Deletes a device from Heketi node
  disable     Disallow usage of a device by placing it offline
  enable      Allows device to go online
  info        Retrieves information about the device
  remove      Removes a device from Heketi node
  resync      Resync storage information about the device with operation system
  rmtags      Removes tags from a device
  settags     Sets tags on a device
###### 3.1. 添加设备
  $ heketi-cli device add \
      --name=/dev/sdb
      --node=3e098cb4407d7109806bb196d9e8f095
      --destroy-existing-data   [可选] 销毁设备上的任何现有数据。
```
[root@glusterfs-node1 ~]# hc device add --name "/dev/sdc" --node f30cea782a8244842f445ffd44d4578e
Device added successfully
```
###### 3.2. 删除设备
删除device前需要先删除volume
要先device disable,然后device remove然后device delete
heketi-cli device disable $ID
keheti-cli device remove $ID
heketi-cli device delete $ID
设备ID可以执行`hc topology info`查看
```shell
[root@glusterfs-node1 ~]# hc device info c5d0de895bfcf8b26fef33991b21ee9c
Device Id: c5d0de895bfcf8b26fef33991b21ee9c
Name: /dev/sdc
State: online
Size (GiB): 9
Used (GiB): 0
Free (GiB): 9
Bricks:
[root@glusterfs-node1 ~]# hc device disable c5d0de895bfcf8b26fef33991b21ee9c
Device c5d0de895bfcf8b26fef33991b21ee9c is now offline
[root@glusterfs-node1 ~]# hc device info c5d0de895bfcf8b26fef33991b21ee9c
Device Id: c5d0de895bfcf8b26fef33991b21ee9c
Name: /dev/sdc
State: offline
Size (GiB): 9
Used (GiB): 0
Free (GiB): 9
Bricks:
[root@glusterfs-node1 ~]# hc device remove c5d0de895bfcf8b26fef33991b21ee9c
Device c5d0de895bfcf8b26fef33991b21ee9c is now removed
[root@glusterfs-node1 ~]# hc device info c5d0de895bfcf8b26fef33991b21ee9c
Device Id: c5d0de895bfcf8b26fef33991b21ee9c
Name: /dev/sdc
State: removed
Size (GiB): 9
Used (GiB): 0
Free (GiB): 9
Bricks:
[root@glusterfs-node1 ~]# hc device delete c5d0de895bfcf8b26fef33991b21ee9c
Device c5d0de895bfcf8b26fef33991b21ee9c deleted
[root@glusterfs-node1 ~]# hc device info c5d0de895bfcf8b26fef33991b21ee9c
Error: Id not found
```
##### 4.volume相关
Usage:
heketi-cli volume [command]

Available Commands:
clone                         Creates a clone
create                        Create a GlusterFS volume
delete                        Deletes the volume
expand                        Expand a volume
info                          Retrieves information about the volume
list                          Lists the volumes managed by Heketi
set-block-hosting-restriction set volume's block hosting restriction
###### 4.1 创建volume
  heketi-cli volume create -h
  --clusters string 指定clusterid
  --size int        volume的大小，单位GiB
  --replica int     指定副本数量，默认3副本
  --replica int     指定volume name
```
[root@glusterfs-node1 ~]# hc volume create --size=1 --name="test" --replica 2 --clusters=6089a20345524da0b7a6559b46a9df62
Name: test
Size: 1
Volume Id: 4a604eac69ca104bb21878afa2b20fad
Cluster Id: 6089a20345524da0b7a6559b46a9df62
Mount: 192.168.189.132:test
Mount Options: backup-volfile-servers=192.168.189.131
Block: false
Free Size: 0
Reserved Size: 0
Block Hosting Restriction: (none)
Block Volumes: []
Durability Type: replicate
Distributed+Replica: 2
```
###### 4.2 查看volume
```
[root@glusterfs-node1 ~]# hc volume list
Id:4a604eac69ca104bb21878afa2b20fad    Cluster:6089a20345524da0b7a6559b46a9df62    Name:test
```
###### 4.3 查看volume详情
```
[root@glusterfs-node1 ~]# hc volume info 4a604eac69ca104bb21878afa2b20fad
Name: test
Size: 1
Volume Id: 4a604eac69ca104bb21878afa2b20fad
Cluster Id: 6089a20345524da0b7a6559b46a9df62
Mount: 192.168.189.132:test
Mount Options: backup-volfile-servers=192.168.189.131
Block: false
Free Size: 0
Reserved Size: 0
Block Hosting Restriction: (none)
Block Volumes: []
Durability Type: replicate
Distributed+Replica: 2
```
###### 4.4 删除volume
```
[root@glusterfs-node1 ~]# hc volume delete 4a604eac69ca104bb21878afa2b20fad
Volume 4a604eac69ca104bb21878afa2b20fad deleted
```
##### 5. 查看整个集群的拓扑
Usage:
  heketi-cli topology [command]

Available Commands:
  info        检索有关当前拓扑的信息
  load        从配置文件添加设备
###### 5.1. 从配置文件导入heketi集群的配置
 heketi-cli topology load --json=<topologyfilename>
导入后会自动创建heketi集群，然后就可以创建glusterfs volume了
官方的一个配置文件
```json
{
    "clusters": [
        {
            "nodes": [
                {
                    "node": {
                        "hostnames": {
                            "manage": [
                                "192.168.10.100"
                            ],
                            "storage": [
                                "192.168.10.100"
                            ]
                        },
                        "zone": 1
                    },
                    "devices": [
                        {
                            "name": "/dev/sdb",
                            "destroydata": false
                        },
                        {
                            "name": "/dev/sdc",
                            "destroydata": false
                        }
                    ]
                },
                {
                    "node": {
                        "hostnames": {
                            "manage": [
                                "192.168.10.101"
                            ],
                            "storage": [
                                "192.168.10.101"
                            ]
                        },
                        "zone": 2
                    },
                    "devices": [
                        {
                            "name": "/dev/sdb",
                            "destroydata": false
                        },
                        {
                            "name": "/dev/sdc",
                            "destroydata": false
                        }
                    ]
                }
            ]
        }
    ]
}
```
###### 4.2. 查看当前拓扑
```json
[root@glusterfs-node1 ~]# hc topology info --json | jq .
{
  "clusters": [
    {
      "volumes": [],
      "nodes": [
        {
          "zone": 1,
          "hostnames": {
            "manage": [
              "192.168.189.132"
            ],
            "storage": [
              "192.168.189.132"
            ]
          },
          "cluster": "6089a20345524da0b7a6559b46a9df62",
          "id": "3f5ec05aebbfbabc4e7c0020a60786ae",
          "state": "online",
          "devices": [
            {
              "name": "/dev/sdc",
              "storage": {
                "total": 10350592,
                "free": 10350592,
                "used": 0
              },
              "id": "c5d0de895bfcf8b26fef33991b21ee9c",
              "state": "online",
              "bricks": []
            }
          ]
        },
        {
          "zone": 1,
          "hostnames": {
            "manage": [
              "192.168.189.131"
            ],
            "storage": [
              "192.168.189.131"
            ]
          },
          "cluster": "6089a20345524da0b7a6559b46a9df62",
          "id": "f30cea782a8244842f445ffd44d4578e",
          "state": "online",
          "devices": [
            {
              "name": "/dev/sdc",
              "storage": {
                "total": 10350592,
                "free": 10350592,
                "used": 0
              },
              "id": "41155d113c94c43126295372f0423490",
              "state": "online",
              "bricks": []
            }
          ]
        }
      ],
      "id": "6089a20345524da0b7a6559b46a9df62",
      "block": true,
      "file": true
    }
  ]
}
```
#### 三、k8s&heketi&glusterfs
##### 1. 创建secret
```yaml
cat > glusterfs_secret.yaml <<EOF
apiVersion: v1
kind: Secret
metadata:
  name: heketi-secret
  namespace: default
data:
  # base64 encoded password. E.g.: echo -n "123456" | base64
  key: MTIzNDU2
type: kubernetes.io/glusterfs
```
##### 2. 创建storageclass
```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: glusterfs
provisioner: kubernetes.io/glusterfs
parameters:
  resturl: "http://10.86.3.113:18080"
  clusterid: "2bfe06768a30c3e464065a86494f663a"
  restauthenabled: "true"
  restuser: "admin"
  secretNamespace: "default"
  secretName: "heketi-secret"
```
##### 2. 创建pvc
```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: glusterfs-test
#  annotations:
#    volume.beta.kubernetes.io/storage-class: "glusterfs"
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
  storageClassName: glusterfs
```

#### FAQ heketi管理gluster常见问题
1. 添加node失败
$ hc  node add  --cluster=6089a20345524da0b7a6559b46a9df62 --management-host-name=192.168.189.131 --sto
rage-host-name=192.168.189.131 --zone=1
Error: New Node doesn't have glusterd running
a. gluster确实没起来
b. heketi 使用的ssh配置有问题，比如keyfile或者user错误
c. ssh没有配置免密

1. failed: node1 is either already part of another cluster or having volumes configured
gluster节点可能未关闭防火墙导致相互之间端口被挡住，可直接关闭防火墙或者放开端口限制

1. 添加device失败
$ hc device add --name "/dev/sdc" --node 3f5ec05aebbfbabc4e7c0020a60786ae
Error: ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain
检查当前节点和添加设备的节点免密是否正常